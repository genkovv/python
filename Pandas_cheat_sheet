import pandas as pd
import numpy as np
from pandas import ExcelWriter
from pandas import ExcelFile
import os
import glob
import pandas as pd
import seaborn as sns
import gc
import warnings
warnings.filterwarnings('ignore') - clears all warnings

------------------------------------------------------------------------------------------------------------------------------
Pandas options
-------------------------------------------------------------------------------------------------------------------------------
pd.options.display.float_format = "{:.1f}".format - List the number without "e" by allowing one number after .
n=.4e10; print(f'{n:f}') - present all numbers after the 
pd.options.mode.chained_assignment=None  - Stop the warning message about ""
pd.get_option('display.max_rows')
pd.set_option('display.max_rows', None) - clear row limit ("Warning")
pd.get_option('display.max_columns')
pd.set_option('display.max_columns',None) - clear column limit
pd.describe_option() -  offline documentation  
pd.reset_option('all') - reset all options
pd.options.display.max_columns = None - List all columns

------------------------------------------------------------------------------------------------------------------------------
df=pd.read_excel(C/path/to/file.xlsx",sheet_name"Sheet1") - Import excel spreadshet`s Sheet1
df = pd.read_csv("bad-file.csv", error_bad_lines=False)  - Ignore bad lines
df = pd.concat(map(pd.read_csv, glob.glob(os.path.join('', "P:\Documents\Docs\Data scientist\Hackathon2\hackathon_data-master\eli_df_hackathon*.csv")))) - import list of csv files to dataframe.
------------------------------------------------------------------------------------------------------------------------------
Export data to excel
------------------------------------------------------------------------------------------------------------------------------
writer = ExcelWriter('Pandas-Example2.xlsx')
df.to_excel(writer,'Sheet1',index=False)
writer.save()
------------------------------------------------------------------------------------------------------------------------------
Cleaning data
------------------------------------------------------------------------------------------------------------------------------
dfu.isnull().sum()  -  Check which columns include Nan
dfu.isnull().values.any() - CHeck if there is at least one Nan
df["column"].fillna(10, inplace=True)  - Replace Nan with 10
df.apply(axis=0, func=lambda x : any(pd.isnull(x)))   - Check if a column has null value
df=df.astype({"column1":int64}) - change column type
dbf=json_normalize(dfa["column1"])   - cnvert json column to pandas dataframe
df=df.dropna() - remove all rows where a cell value and requires to reset the index
df.reset_index(inplace=True)
newtext=re.search("\/.*",text).group(0)  - Use regular expression to get portion of the string and assign it to a new text

------------------------------------------------------------------------------------------------------------------------------
 Create new dataframe from two series where the indexes are identical and lenth
 
 matchdf=pd.DataFrame({'y_predicted':y_pred.values, 'y_test':y_test.values})

------------------------------------------------------------------------------------------------------------------------------

Columns:

df[["column1,column2"]]  - list two columns
df.sort_values(by="car", ascending=True)   - Sort column "car" from A-Z
df[["column_name"]] - list only one column 
df.rename(columns={"A":"a"},inplace=True) - renames columns "A" with "a"
df["column"] = df["column"].replace(r"\ ","",regex=True)     - remove spaces in columns
df.column-name = df.column-name.str.replace(' ', '')     - 
df.columns = df.columns.str.lstrip() -  To remove white space at the beginning of string
df.columns = df.columns.str.rstrip() - 
df.rename(columns={"hp":"bhp"},inplace=True) - rename column hp to bhp
df[df.column-name.str.contains("F[AE]LL.*BI[KC]")] - filter column based on regular expression
df[(df["column1"]=="string1") & (df["column5"]=="string2")] - Filter the dataframe for specific strings in two columns.
------------------------------------------------------------------------------------------------------------------------------
Sorting:

a=dataset["age"].unique(); sorted(a); print(a) - List sorted unique values.
------------------------------------------------------------------------------------------------------------------------------

df.shape - will show number of rows [0] and colums [1]
df.info                                                      - will list the name and number of columns, number of rows  
df = df.reset_index() - re-create the index after small dataframe is cut from large
del df['index']      - delete column "index"
df.drop('column_name', axis=1, inplace=True) - delete / drop column name
------------------------------------------------------------------------------------------------------------------------------
Change values:

df.loc[(df['column_1'] > 100) & (df["column_2"]<=10),"column8"]=1 - Change cell in column8 to 1 if column1>100 and column2<=10
df1=df.loc[((df["column1"]<=17)&(df["column1"]>=13))]  -  lists values in column1 which are between or eaqual to 13 =><=17
df.loc[df["column1]=="NaN"]="0"                           - Changes the cells which contain NaN to 0
df.loc[df['First Season'] > 1990, 'First Season'] = 1    
df[df['bhp'] > 100]                                      - List all columns where cells in column bhp are > 100
df[(df['column1'] > 100) & (df["column2"]<=10)]          - List all columns where "column1" > 100 and column2<=10 (OR |, equal == )
df["column1"]=df["column1"].replace(["?"],"NA")  - replaces string "?" with NA in column "column1"
df1=df.iloc[0:10]  - creating new df1 with all columns and 10 rows
df1=df.iloc[0:10,0:10]  - creating new df1 with all columns and 10 rows
df3=pd.merge(df1,df2[["col-name","colname5","colname7"]],on="col-name",how="left")  - VLOOKUP equivalent (column) both df need to have identical "col-name" column
df=df.rename({"oldname_col":"newname_col"},axis="columns") - rename column 
df[df["column-name"].str.contains("tch")]   - list all columns where string includes "tch" in column "column-name"
df1=df[df["body-style"].str.match("^ha.*p$")] - using regular expression
df.row.str.extract('(?P<fips>\d{5})((?P<state>[A-Z ]*$)|(?P<county>.*?), (?P<state_code>[A-Z]{2}$))') - matches 5 dgits from column "fips"
df["brand"].str.extract("([A-Z][a-z].*)") - capture with regular expression

------------------------------------------------------------------------------------------------------------------------------

Groupby

df.groupby(['col1','col2']).agg({'col3':'sum','col4':'sum'}).reset_index()   - group by col1 and col2 and sum by col4 and col4

------------------------------------------------------------------------------------------------------------------------------

List:

df["bhp"].unique() - List unique values in a column
list.reverse() - reversed the list
pd.crosstab(df['job'],[df['maritalStatus'],df['subscribed']]) - creates a table and lists all unique "job" values on y axis and "material" and subscribe status on x axis and their total count.

------------------------------------------------------------------------------------------------------------------------------
Select sertain columns based on data type
------------------------------------------------------------------------------------------------------------------------------
dfO=df.select_dtypes(include=["object"]) - It will create new dataframe based on the column types "object"

------------------------------------------------------------------------------------------------------------------------------
Convert rows from dataset in a content in list
------------------------------------------------------------------------------------------------------------------------------
temp=[]

for row in lottopd.iterrows():
    index, data = row
    temp.append(data.tolist())
---------------------------------------------------------------------------------------------------------------------------
Apend series of a line in dataframe:

s= pd.Series([80,2,50]),index=["column1","column2","column3"]) -  Append to df2`s columns the values in s Series.
df2=df1.append(s, ignore_index=True)


------------------------------------------------------------------------------------------------------------------------------
Unzip a file

zip_ref = zipfile.ZipFile("P:\Documents\Docs\Data scientist\Hackathon2\hackathon_data-master.zip", 'r')
zip_ref.extractall("P:\Documents\Docs\Data scientist\Hackathon2")
zip_ref.close()

------------------------------------------------------------------------------------------------------------------------------
Visualisation:

plt.ticklabel_format(style='plain', axis='y') - Change exponential presentation of numbers to standard values. 
sns.set(rc={'figure.figsize':(14,12)}) - Change the graph size
df.plot(x="col1", y="col2",kind="bar",color = 'g',figsize=(20,7),fontsize=16,legend="full") - Create barchart 
plt.xticks(rotation=0) - Rotate the x axis legend horizontaly 
plt.ticklabel_format(style='plain', axis='y')  - make y axis show full numbers
plt.legend(loc=1, prop={'size': 14}) - plot legend size and location

